{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "总结：为了在计算q-k的atten-score时，加入两个token之间的位置信息， 需要在q-k上加上rope\n",
    "参考：https://zhuanlan.zhihu.com/p/667864459\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_theta\u001B[39m(dim: \u001B[38;5;28mint\u001B[39m, base: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10000.0\u001B[39m, device: torch\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m    计算旋转位置编码中的 Theta 角度值。\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03m    - torch.Tensor: 包含Theta值的1D张量, 形状为 [d/2]。\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_theta(dim: int, base: float = 10000.0, device: torch.device = torch.device('cpu')) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    计算旋转位置编码中的 Theta 角度值。\n",
    "\n",
    "    参数：\n",
    "    - d (int): 嵌入向量的维度（必须为偶数）。\n",
    "    - base (float): 基础频率参数, 默认为10000.0。\n",
    "    - device (torch.device): 计算设备, 默认为CPU。\n",
    "\n",
    "    返回：\n",
    "    - torch.Tensor: 包含Theta值的1D张量, 形状为 [d/2]。\n",
    "    \"\"\"\n",
    "    if dim % 2 != 0:\n",
    "        print(\"嵌入维度 dim 必须为偶数\") # 因为 需要使用 10000**-2i/d 计算，所以 dim 必须为偶数，三角式绝对位置编码 Pk，2i = sin（k/10000**2i/d）\n",
    "\n",
    "    i = torch.arange(1, (dim//2) + 1, dtype=torch.float32, device=device) # range因为范围限制，最大取到 dim//2\n",
    "    theta_i = base ** (-2*(i - 1) / dim)\n",
    "\n",
    "    return theta_i\n",
    "\n",
    "def precompute_freqs_cis(dim: int, seq_len: int, base: float = 10000.0, device: torch.device = torch.device('cpu')):\n",
    "    theta = compute_theta(dim, base, device) # theta 角度值序列，向量, 大小为 dim // 2\n",
    "    m = torch.arange(seq_len, device=device) # # token 位置值序列，向量，大小为 seq_len\n",
    "    m_theta = torch.outer(m, theta) # m的seq_len长度的每个位置，都乘以维度为dim//2的 theta，所有 token 位置的所有 Theta 值范围, 矩阵，尺寸为 [seq_len, dim // 2]\n",
    "    freqs_cis = torch.polar(torch.ones_like(m_theta), m_theta) # e^{i*m*\\theta}，本质上是旋转矩阵\n",
    "    return freqs_cis\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis, x):\n",
    "    ndim = x.ndim\n",
    "    assert ndim >= 2\n",
    "    assert freqs_cis.shape == (x.shape[1],x.shape[-1]), \"the last two dimension of freqs_cis, x must match\"\n",
    "    shape = [d if i==1 or i==ndim-1 else 1 for i,d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor, device: torch.device = torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "        - x_q(torch.Tensor): 实际上是权重 W_q * 词嵌入向量值, 来自上一个线性层的输出, 形状为 [batch_size, seq_len, n_heads, head_dim]\n",
    "        - x_k(torch.Tensor): 实际上是权重 W_k * 词嵌入向量值, 来自上一个线性层的输出, 形状为 [batch_size, seq_len, n_heads, head_dim]\n",
    "        - freqs_cis (torch.Tensor): 频率复数张量, 形状为 [max_seq_len, head_dim]\n",
    "    返回:\n",
    "        - Tuple[torch.Tensor, torch.Tensor]: 旋转编码后的查询和键张量\n",
    "    \"\"\"\n",
    "    # 实数域张量转为复数域张量\n",
    "    xq_reshape = xq.reshape(*xq.shape[:-1], -1, 2) # [batch_size, seq_len, dim] -> [batch_size, seq_len, dim//2, 2]\n",
    "    xk_reshape = xk.reshape(*xk.shape[:-1], -1, 2) # [batch_size, seq_len, dim] -> [batch_size, seq_len, dim//2, 2]\n",
    "    xq_complex = torch.view_as_complex(xq_reshape) # 复数形式张量\n",
    "    xk_complex = torch.view_as_complex(xk_reshape) # 复数形式张量\n",
    "\n",
    "    # 旋转矩阵（freqs_cis）的维度在序列长度（seq_len，维度 1）和头部维度（head_dim，维度 3）上需要与嵌入的维度一致。\n",
    "    # 此外，freqs_cis 的形状必须与 xq 和 xk 相匹配，因此我们需要将 freqs_cis 的形状从 [max_seq_len, head_dim] 调整为 [1, max_seq_len, 1, head_dim]。\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_complex) # [max_seq_len, 1, 1, dim // 2]\n",
    "\n",
    "    # 应用旋转操作，并将结果转回实数域\n",
    "    xq_out = torch.view_as_real(xq_complex * freqs_cis).flatten(3) # flatten(2) 将后面两个维度压成一个维度\n",
    "    xk_out = torch.view_as_real(xk_complex * freqs_cis).flatten(3)\n",
    "\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T09:44:21.668400Z",
     "start_time": "2025-01-07T09:44:21.051452400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
