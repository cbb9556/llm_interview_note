[Scia Reto](https://sciareto.org) mind map   
> __version__=`1.1`,showJumps=`true`
---

# 38\-大模型（LLMs）强化学习<br/>—— PPO 面
> mmd.emoticon=`tree`


## 38 PPO

### 大语言模型RLHF中的PPO 分为：

#### 1\. 采样

#### 2\. 反馈

#### 3\. 学习

#### policy\_model = load\_model\(\)<br/>for k in range\(20000\):<br/> \# 采样（生成答案）<br/> prompts = sample\_prompt\(\)<br/> data = respond\(policy\_model, prompts\)<br/> <br/> \# 反馈（计算奖励）<br/> rewards = reward\_func\(reward\_model, data\)<br/> <br/> \# 学习（更新参数）<br/> for epoch in range\(4\):<br/> policy\_model = train\(policy\_model, prompts, data, rewards\)<br/>
> align=`left`


### PPO的理论

#### 39 pdf 没讲清楚

### 整个八股文都没讲清楚
