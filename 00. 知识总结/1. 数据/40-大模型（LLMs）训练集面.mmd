[Scia Reto](https://sciareto.org) mind map   
> __version__=`1.1`,showJumps=`true`
---

# The Root Topic
> mmd.emoticon=`tree`


## 40 训练集面

### SFT（有监督微调）的数据集格式

#### 一问一答

### RM（奖励模型）的数据格式？

#### 一个问题 \+ 一条好回答样例 \+ 一条差回答样例

### PPO（强化学习）的数据格式？

#### 不需要新增数据。需要提供一些prompt，可以直接用sft阶段的问。另外，需要限制<br/>模型不要偏离原模型太远（ptx loss），也可以直接用sft的数据。

### 找数据集哪里找？

#### 推荐Alpaca\-COT，数据集整理的非常全，眼花缭乱。

#### CoT微调数据集：Alpaca\-CoT 里面包括常用的alpaca，CoT等数据集，有中文的。

### 微调需要多少条数据？

#### 取决于预训练数据和微调任务的数据分布是否一致

##### 分布一致，100条就够

##### 分布差异大就需要多<br/>些数据，千条或者万条以上为佳。

#### 自己的任务复杂或者下游任务行业比较冷门

##### 如药品名称识别任务，则需要较多监督数据

##### 还有微调大模型时，一遍是记不住的。<br/>100条的微调数据，epochs=20才能稳定拟合任务要求。

### 有哪些大模型的训练集？

#### 预训练数据集togethercomputer/RedPajama\-Data\-1T「红睡衣」开源计划

##### 高质量、大规模、高覆盖度的预训练数据集；

##### 在预训练数据集上训练出的基础模型；

##### • 指令调优数据集和模型，比基本模型更安全、可靠。

#### 预训练数据集RedPajama\-Data\-1T已开源，包括七个子集

#### 经过预处理后得到的token数量大致可<br/>以匹配Meta在原始LLaMA论文中报告的数量，并且数据预处理相关脚本也已开源。

#### 完整的RedPajama\-Data\-1T数据集需要的存储容量为压缩后3TB，解压后5TB。

### 进行领域大模型预训练应用哪些数据集比较好？

#### 现有的开源大模型进行预训练的过程中会加入数据、论文等数据。

##### 因为这些数<br/>据的数据质量较高，领域相关性比较强，知识覆盖率（密度）较大，可以让模型更适应考试

##### 时领域相关的网站内容、新闻内容也是比较重<br/>要的数据。

### 如何选取和构建大模型微调数据？

#### 1\. 数据的多样性：

##### 多样性即为数据的去重，去重这件事的核心是相似度度量

##### 现在的相似度度量方法大家用的比较多<br/>的是基于对比学习构造的语义向量这套思路，<br/>当然简单的基于词袋或者tfidf的方案也是可以的

##### 核心的相似度度量方法后，我们可以使用简单的onepass聚类方法进行过滤，

###### 使用带优化目标的聚类：比如K\-Center\-Greedy算法，其约束条件是在最大化多样性<br/>的情况下，使指令数据集最小。

##### 如果我们已经有了一批已经去重的人工处理过的高质量数据，<br/>如何寻找与这批数据不一样的数据呢？

###### 简单地把已有的数据全部当成正样本打上1，然后待筛选的数据全部当成负样本打上0

###### 使用deberta等构建二分类模型，并进行K\-fold的交叉验证，在交叉验证过程中，选出每一个fold过程<br/>中的测试集合里概率接近于0的样本。

###### 就能把长得与已有数据不一样的数据给选出来了，

#### 数据的不确定性。

##### 有了质量打分模型后，我们就可以判断一些指令数据的质量高低，并且据此选出模型真正不确定的<br/>数据。

##### 手动的拒绝采样，核心是选择“模型不确定”\+“数据质量达标”的那部分数据。
